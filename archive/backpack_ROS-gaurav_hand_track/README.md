# backpack_ROS path planning and control 

The goal of this project is to enable the backpack arm to recognize obstables in its surrounding environment and to plan a path that avoids these obstacles given its end goal. Currently, the path planning algorithm the robot arm uses is RRTConnect. The visualization, simulation, and control of the backpack is achieved through the Rviz plugins. For visualization, a backpack urdf model is imported to Rviz. The Rviz visual graph also displays the octomap contructed by the real time sensors. For simulation and control, the user can choose the start/end states he or she wishes the robot arm to plan a path according to, or choose a predefined pose in Rviz. The user can then send commands to the robot directly to plan a path and execute the trajectory between these poses.  

The backpack_config file is the configuration file generated by the Moveit Setup Assistant.The move_backpack file contains python scripts that enables the backpack arm to move in Rviz or physically. "hebi_move_to_pose.py" is the python scripts that commands the robot through listening to "/joint_state" messages in rviz. The purpose and usage of other python scripts are described in the comments of the relative files. The combine file simply contains a convenient launch file that loads all of the dependency files to start the demo. 

Most of the individual pieces of the robot arm is extraced from the orginal hebi library https://github.com/HebiRobotics/HEBI-ROS/tree/master/hebiros_description. I slightly modified it and added the full robot urdf in the hebiros_description package. To enable catkin_make, the user should install the dynamic_reconfigure package from https://github.com/ros/dynamic_reconfigure. To load the real senses, the user should install realsense-ros-2.2.6. To enable control of the backpack arm, one needs to install the dependency packages https://github.com/HebiRobotics/HEBI-ROS/tree/master/hebiros. The user should also have moveit and rtabmap installed to enable move_group control and mapping. 


## TO run aruco marker detection
### For the first timers
Run
```
	source installall.sh
	cd src/aruco_detect_ros/src
	chmod +x getposes.py
```
Connect the intel camera and then run
```
	roslaunch realsense2_camera rs_camera.launch 		 	#Launches the camera
	roslaunch aruco_detect_ros aruco_intel_finder.launch 	#Launches the aruco marker detections
```
If this works its great! Congratualations you cracked the Enigma Code

### For running regularly
Make using
```
	source makeall.sh
	
	#LUDI launch file 
	roslaunch realsense2_camera rs_camera.launch #Launches the camera
	roslaunch aruco_detect_ros aruco_intel_finder.launch #Launches the aruco marker detections
	rosrun aruco_detect_ros getposes.py
```
If this works. Congratulations! you cracked Camellia cypher. 


## To run Hand Detection
first make sure that you ran 
````
source installall.sh
````
Then for running the script you need to enable virtual enviroment for which you run 
````
source sourceall.sh
````
After source you can run the file directly as
````
rosrun nn_detect_hand get_hand_poses.py
````
if you are not calling the file or the sequence of directory changes you might wanna change the file 

````
subl src/nn_detect_hand/src/include/utils/detector_utils.py
#change line of MODEL_NAME, default on line 20
````
debugging if you encounter pcObjectype kind of error do
````
cd /opt/ros/kinetic/lib/python2.7/dist-packages/
sudo mv cv2.so cv2_ros.so
sudo apt-get install python3-catkin-pkg-modules python3-rospkg-modules
sudo apt-get install python-catkin-tools python3-dev python3-catkin-pkg-modules python3-numpy python3-yaml ros-kinetic-cv-bridge
````
then go to your workspace
````
cd /to/your/workspace/
catkin config -DPYTHON_EXECUTABLE=/usr/bin/python3 -DPYTHON_INCLUDE_DIR=/usr/include/python3.5m -DPYTHON_LIBRARY=/usr/lib/x86_64-linux-gnu/libpython3.5m.so
catkin config --install
git clone https://github.com/ros-perception/vision_opencv.git src/vision_opencv
# Find version of cv_bridge in your repository
apt-cache show ros-kinetic-cv-bridge | grep Version
    Version: 1.12.8-0xenial-20180416-143935-0800
# Checkout right version in git repo. In our case it is 1.12.8
cd src/vision_opencv/
git checkout 1.12.8
cd ../../
# Build
source makeall.sh
# Extend environment with new package
source install/setup.bash --extend
````
if you encounter error like 
````
Could not find the following Boost libraries:

          boost_python3
````
It is because CMake tries to find libboost_python3.so library, but in ubuntu it is libboost_python-py35.so(/usr/lib/x86_64-linux-gnu/libboost_python-py35.so), so you should change line
````
find_package(Boost REQUIRED python3)
````
to
````
find_package(Boost REQUIRED python-py35)
````
in file src/vision_opencv/cv_bridge/CMakeLists.txt and rebuild package. [LINK](https://stackoverflow.com/questions/49221565/unable-to-use-cv-bridge-with-ros-kinetic-and-python3/50291787#50291787)